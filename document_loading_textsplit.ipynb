{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d4c3ab93",
      "metadata": {
        "id": "d4c3ab93"
      },
      "source": [
        "# Document Loading"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2b5f165-b646-41fb-abc8-eb6ab31f5edc",
      "metadata": {
        "id": "f2b5f165-b646-41fb-abc8-eb6ab31f5edc"
      },
      "source": [
        "## Note to students.\n",
        "During periods of high load you may find the notebook unresponsive. It may appear to execute a cell, update the completion number in brackets [#] at the left of the cell but you may find the cell has not executed. This is particularly obvious on print statements when there is no output. If this happens, restart the kernel using the command under the Kernel tab."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af8b8ee8",
      "metadata": {
        "id": "af8b8ee8"
      },
      "source": [
        "## Retrieval augmented generation\n",
        "\n",
        "In retrieval augmented generation (RAG), an LLM retrieves contextual documents from an external dataset as part of its execution.\n",
        "\n",
        "This is useful if we want to ask question about specific documents (e.g., our PDFs, a set of videos, etc)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3334357c",
      "metadata": {
        "id": "3334357c"
      },
      "source": [
        "![overview.jpeg](attachment:overview.jpeg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f015f708",
      "metadata": {
        "height": 30,
        "tags": [],
        "id": "f015f708"
      },
      "outputs": [],
      "source": [
        "# ! pip install langchain openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f26c2a2a-f7a7-4580-ab73-178bab918dd7",
      "metadata": {
        "height": 166,
        "tags": [],
        "id": "f26c2a2a-f7a7-4580-ab73-178bab918dd7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "import sys\n",
        "sys.path.append('../..')\n",
        "from google.colab import userdata\n",
        "\n",
        "# from dotenv import load_dotenv, find_dotenv\n",
        "# _ = load_dotenv(find_dotenv()) # read local .env file\n",
        "\n",
        "openai.api_key  = userdata.get('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38baf6d3",
      "metadata": {
        "id": "38baf6d3"
      },
      "source": [
        "## PDFs\n",
        "\n",
        "Let's load a PDF [transcript](https://see.stanford.edu/materials/aimlcs229/transcripts/MachineLearning-Lecture01.pdf) from Andrew Ng's famous CS229 course! These documents are the result of automated transcription so words and sentences are sometimes split unexpectedly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab4583ef",
      "metadata": {
        "height": 64,
        "tags": [],
        "id": "ab4583ef"
      },
      "outputs": [],
      "source": [
        "# The course will show the pip installs you would need to install packages on your own machine.\n",
        "# These packages are already installed on this platform and should not be run again.\n",
        "#! pip install pypdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "821863bb",
      "metadata": {
        "id": "821863bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b18d74f8-b0c8-43ae-dab5-d81fe2ddc60a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.2.7-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.9.5)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: langchain<0.3.0,>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.9)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.21)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.1.92)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.31.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (8.5.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.7->langchain-community) (0.2.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.7->langchain-community) (2.8.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.12->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.12->langchain-community) (24.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (3.10.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.7.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.12->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.7->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.7->langchain-community) (2.20.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.7 langchain-community-0.2.7 marshmallow-3.21.3 mypy-extensions-1.0.0 typing-inspect-0.9.0\n",
            "Collecting pypdf\n",
            "  Downloading pypdf-4.3.0-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.7/295.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.12.2)\n",
            "Installing collected packages: pypdf\n",
            "Successfully installed pypdf-4.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -U langchain-community\n",
        "!pip install pypdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38ef5d48",
      "metadata": {
        "height": 64,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38ef5d48",
        "outputId": "f7f5feca-b6ef-4f4a-bb13-ea18b2b86d03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuroOF8v1TNg",
        "outputId": "789d8b6b-2a87-4fd3-e7bf-fd77efe5f6fb"
      },
      "id": "vuroOF8v1TNg",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loader = PyPDFLoader(\"2406.11903v1.pdf\")\n",
        "pages = loader.load()"
      ],
      "metadata": {
        "id": "n9hgLw7y15Iu"
      },
      "id": "n9hgLw7y15Iu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "a284cc8a",
      "metadata": {
        "id": "a284cc8a"
      },
      "source": [
        "Each page is a `Document`.\n",
        "\n",
        "A `Document` contains text (`page_content`) and `metadata`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd28c723-3625-4219-b0f8-8d5b761ae79e",
      "metadata": {
        "height": 30,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fd28c723-3625-4219-b0f8-8d5b761ae79e",
        "outputId": "08e52347-8c96-4c2e-dc77-eed56b3f7d2d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "39"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "len(pages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26ff4112",
      "metadata": {
        "height": 30,
        "tags": [],
        "id": "26ff4112"
      },
      "outputs": [],
      "source": [
        "page = pages[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c94e3b5",
      "metadata": {
        "height": 30,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5c94e3b5",
        "outputId": "55bc8e99-21d8-424f-c728-c971b98ecb80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "A Survey of Large Language Models for\n",
            "Financial Applications: Progress,\n",
            "Prospects and Challenges\n",
            "Yuqi Nie∗, Y axuan Kong∗, Xiaowen Dong, John M. Mulvey†‡, H. Vincent Poor,\n",
            "Qingsong Wen, Stefan Zohren†\n",
            "Abstract —Recent advances in large language models (LLMs) have unlocked novel opportunities for machine learning applications in\n",
            "the financial domain. These models have demonstrated remarkable capabilities in understanding context, processing vast amounts of\n",
            "data, and generating human-preferred c\n"
          ]
        }
      ],
      "source": [
        "print(page.page_content[0:500])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "605d0932",
      "metadata": {
        "height": 30,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "605d0932",
        "outputId": "5e1d347a-f3b6-4520-a884-e289cca9c1a4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'source': '2406.11903v1.pdf', 'page': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "page.metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ead28868",
      "metadata": {
        "id": "ead28868"
      },
      "source": [
        "## YouTube"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c5f360f",
      "metadata": {
        "height": 64,
        "tags": [],
        "id": "4c5f360f"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders.generic import GenericLoader\n",
        "from langchain.document_loaders.parsers import OpenAIWhisperParser\n",
        "from langchain.document_loaders.blob_loaders.youtube_audio import YoutubeAudioLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4835edd9",
      "metadata": {
        "height": 47,
        "tags": [],
        "id": "4835edd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 707
        },
        "outputId": "67aaf9ae-ac40-4384-8a5a-087fb06ef644"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting yt_dlp\n",
            "  Downloading yt_dlp-2024.7.16-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting brotli (from yt_dlp)\n",
            "  Downloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from yt_dlp) (2024.7.4)\n",
            "Collecting mutagen (from yt_dlp)\n",
            "  Downloading mutagen-1.47.0-py3-none-any.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycryptodomex (from yt_dlp)\n",
            "  Downloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests<3,>=2.32.2 (from yt_dlp)\n",
            "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<3,>=1.26.17 in /usr/local/lib/python3.10/dist-packages (from yt_dlp) (2.0.7)\n",
            "Collecting websockets>=12.0 (from yt_dlp)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.32.2->yt_dlp) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.32.2->yt_dlp) (3.7)\n",
            "Installing collected packages: brotli, websockets, requests, pycryptodomex, mutagen, yt_dlp\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed brotli-1.1.0 mutagen-1.47.0 pycryptodomex-3.20.0 requests-2.32.3 websockets-12.0 yt_dlp-2024.7.16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "requests"
                ]
              },
              "id": "84977290399846aa9235fc7a1eee4e0f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "! pip install yt_dlp\n",
        "! pip install pydub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install pydub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5y5tBRdC2QNd",
        "outputId": "3c0b638d-c597-4b61-e539-8f3c0bfa4a42"
      },
      "id": "5y5tBRdC2QNd",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydub\n",
            "  Using cached pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e46b9fa5",
      "metadata": {
        "id": "e46b9fa5"
      },
      "outputs": [],
      "source": [
        "# !pip install ffmpeg"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "adaa8f7a-bd04-4bbd-96a9-8c2088426885",
      "metadata": {
        "id": "adaa8f7a-bd04-4bbd-96a9-8c2088426885"
      },
      "source": [
        "**Note**: This can take several minutes to complete."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "197f0936",
      "metadata": {
        "height": 132,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "197f0936",
        "outputId": "f7b23ad3-991e-46d4-8619-c5287d7a9695"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] Extracting URL: https://youtu.be/MoIguQfHUcY\n",
            "[youtube] MoIguQfHUcY: Downloading webpage\n",
            "[youtube] MoIguQfHUcY: Downloading ios player API JSON\n",
            "[youtube] MoIguQfHUcY: Downloading m3u8 information\n",
            "[info] MoIguQfHUcY: Downloading 1 format(s): 140\n",
            "[download] docs/youtube//台積電高效能運算 HPC 業績佔比快速成長，AI 與 NVIDIA 或許是最大原因？！#ai #台積電 #HPC #人工智慧 #台積電法說會 #高效能運算 #晶圓代工 #llm #大型語言模型.m4a has already been downloaded\n",
            "[download] 100% of    1.05MiB\n",
            "[ExtractAudio] Not converting audio docs/youtube//台積電高效能運算 HPC 業績佔比快速成長，AI 與 NVIDIA 或許是最大原因？！#ai #台積電 #HPC #人工智慧 #台積電法說會 #高效能運算 #晶圓代工 #llm #大型語言模型.m4a; file is already in target format m4a\n",
            "Transcribing part 1!\n"
          ]
        }
      ],
      "source": [
        "url=\"https://youtu.be/MoIguQfHUcY\"\n",
        "save_dir=\"docs/youtube/\"\n",
        "loader = GenericLoader(\n",
        "    YoutubeAudioLoader([url],save_dir),\n",
        "    OpenAIWhisperParser(api_key=userdata.get('OPENAI_API_KEY'))\n",
        ")\n",
        "docs = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2bf39c3",
      "metadata": {
        "height": 30,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "c2bf39c3",
        "outputId": "98b7cfaf-c1b8-4bcd-bcbe-310ae0e5b279"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'今天下午台積電廠他們的法說會公布了2024年D2G的業績概況 其中在HPC這一項成長幅度驚人 然而什麼是HPC呢 HPC是High Performance Computing高效能運算的一個簡稱 那主要會運用在大型的這種伺服器大型的製造中心裡面 那目前大家可以猜想像是這種AI相關的製造運算 可以用在像是天氣模擬或者是各種AI人工智慧的一些相關的運用 像是我們去訓練大型語言模型去做所謂的pre-train 事先訓練利用大量的文本去訓練 以及像是這種越來越大型的語言模型的參數 都需要這種高效能運算的support 那大家可以猜想而知他絕對跟NVIDIA這間公司所生產的這種GPU有個絕對的關係 NVIDIA即將上市的Blackwell號稱他們是全世界目前最好的這種AI運算的中心 也就是說他可能跟TSMC也就是台積電現在的業績其實是有高度相關的 當然我們可以看到隨著TSMC台積電他們的業績 在HPC這一塊的相對應高速成長 我們大概可以知道對AI的運算這一塊還是有非常強烈的需求 接下來我們可以更期待這樣子的一個AI的運算的結果對我們產生什麼樣的影響'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "docs[0].page_content[0:500]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b54e6f9",
      "metadata": {
        "id": "6b54e6f9"
      },
      "source": [
        "## URLs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ede7f5d4",
      "metadata": {
        "height": 64,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ede7f5d4",
        "outputId": "5d838370-a43a-419b-a5d4-925447e31070"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        }
      ],
      "source": [
        "from langchain.document_loaders import WebBaseLoader\n",
        "\n",
        "loader = WebBaseLoader(\"https://github.com/basecamp/handbook/blob/master/37signals-is-you.md\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "596c8f4e-6fd5-4230-9dfc-84e100e90d72",
      "metadata": {
        "height": 30,
        "tags": [],
        "id": "596c8f4e-6fd5-4230-9dfc-84e100e90d72"
      },
      "outputs": [],
      "source": [
        "docs = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3039f8ed-ebc1-44e7-829a-9499dc5d1f03",
      "metadata": {
        "height": 30,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "3039f8ed-ebc1-44e7-829a-9499dc5d1f03",
        "outputId": "7b93f12c-6fc9-44d0-ead7-6004ae2ba49d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "File not found · GitHub\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Skip to content\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Navigation Menu\n",
            "\n",
            "Toggle navigation\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "            Sign in\n",
            "          \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "        Product\n",
            "        \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Actions\n",
            "        Automate any workflow\n",
            "      \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Packages\n",
            "        Host and manage packages\n",
            "      \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Security\n",
            "        Find and fix vulnerabilities\n",
            "      \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Codes\n"
          ]
        }
      ],
      "source": [
        "print(docs[0].page_content[:500])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter"
      ],
      "metadata": {
        "id": "NEDz8bVv5Ija"
      },
      "id": "NEDz8bVv5Ija",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunk_size = 26\n",
        "chunk_overlap = 4"
      ],
      "metadata": {
        "id": "_5mDVmBP5InB"
      },
      "id": "_5mDVmBP5InB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=chunk_size,\n",
        "    chunk_overlap=chunk_overlap\n",
        ")\n",
        "c_splitter = CharacterTextSplitter(\n",
        "    chunk_size=chunk_size,\n",
        "    chunk_overlap=chunk_overlap\n",
        ")"
      ],
      "metadata": {
        "id": "1eX9xkCD5OyC"
      },
      "id": "1eX9xkCD5OyC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text1 = 'abcdefghijklmnopqrstuvwxyz'"
      ],
      "metadata": {
        "id": "sdVkVtvp5R0Z"
      },
      "id": "sdVkVtvp5R0Z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r_splitter.split_text(text1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKTbaCUW5VOf",
        "outputId": "0d381aa3-fdce-462f-8349-09d16e051184"
      },
      "id": "MKTbaCUW5VOf",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['abcdefghijklmnopqrstuvwxyz']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text2 = 'abcdefghijklmnopqrstuvwxyzabcdefg'"
      ],
      "metadata": {
        "id": "FJv2JWfC5XXH"
      },
      "id": "FJv2JWfC5XXH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r_splitter.split_text(text2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXIKHsYv5Z1z",
        "outputId": "16f298c8-248f-4c04-f896-a7c6d030badc"
      },
      "id": "iXIKHsYv5Z1z",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['abcdefghijklmnopqrstuvwxyz', 'wxyzabcdefg']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text3 = \"a b c d e f g h i j k l m n o p q r s t u v w x y z\"\n",
        "r_splitter.split_text(text3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oH2hZfiU5bYE",
        "outputId": "914a8170-4d36-4dc9-e0b5-50c3db94ee18"
      },
      "id": "oH2hZfiU5bYE",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a b c d e f g h i j k l m', 'l m n o p q r s t u v w x', 'w x y z']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c_splitter.split_text(text3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxEA5deW5iA5",
        "outputId": "a7ee260f-4a18-4f6e-e02d-871765ed3e9a"
      },
      "id": "pxEA5deW5iA5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a b c d e f g h i j k l m n o p q r s t u v w x y z']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c_splitter = CharacterTextSplitter(\n",
        "    chunk_size=chunk_size,\n",
        "    chunk_overlap=chunk_overlap,\n",
        "    separator = ' '\n",
        ")\n",
        "c_splitter.split_text(text3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PeBu_NPB5m0P",
        "outputId": "2173ef28-2294-41ad-c966-d72b55620ac4"
      },
      "id": "PeBu_NPB5m0P",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a b c d e f g h i j k l m', 'l m n o p q r s t u v w x', 'w x y z']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c_splitter = CharacterTextSplitter(\n",
        "    chunk_size=chunk_size,\n",
        "    chunk_overlap=chunk_overlap,\n",
        "    separator = ' '\n",
        ")\n",
        "c_splitter.split_text(text3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4buj6io75tUo",
        "outputId": "189fc374-2767-4650-b2c2-c5d82496ca4e"
      },
      "id": "4buj6io75tUo",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a b c d e f g h i j k l m', 'l m n o p q r s t u v w x', 'w x y z']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -qU langchain-text-splitters"
      ],
      "metadata": {
        "id": "1Qh2gmnP8iRx"
      },
      "id": "1Qh2gmnP8iRx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter"
      ],
      "metadata": {
        "id": "XWptOCZa8l8q"
      },
      "id": "XWptOCZa8l8q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=chunk_size,\n",
        "    chunk_overlap=chunk_overlap\n",
        ")"
      ],
      "metadata": {
        "id": "N-cifUlz8pdF"
      },
      "id": "N-cifUlz8pdF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text3 = \"a b c d e f g h i j k l m n o p q r s t u v w x y z\"\n",
        "r_splitter.split_text(text3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWGtwsZ88tmw",
        "outputId": "5be67127-cb05-47c5-b575-87f0954d5cce"
      },
      "id": "PWGtwsZ88tmw",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a b c d e f g h i j k l m', 'l m n o p q r s t u v w x', 'w x y z']"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "some_text = \"\"\"When writing documents, writers will use document structure to group content. \\\n",
        "This can convey to the reader, which idea's are related. For example, closely related ideas \\\n",
        "are in sentances. Similar ideas are in paragraphs. Paragraphs form a document. \\n\\n  \\\n",
        "Paragraphs are often delimited with a carriage return or two carriage returns. \\\n",
        "Carriage returns are the \"backslash n\" you see embedded in this string. \\\n",
        "Sentences have a period at the end, but also, have a space.\\\n",
        "and words are separated by space.\"\"\""
      ],
      "metadata": {
        "id": "QyzSv5x98y-f"
      },
      "id": "QyzSv5x98y-f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(some_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-RaF5KZ8_55",
        "outputId": "358bb45f-90c7-499d-cad1-7726a9b36575"
      },
      "id": "t-RaF5KZ8_55",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "496"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c_splitter = CharacterTextSplitter(\n",
        "    chunk_size=450,\n",
        "    chunk_overlap=0,\n",
        "    separator = ' '\n",
        ")\n",
        "r_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=450,\n",
        "    chunk_overlap=0,\n",
        "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
        ")"
      ],
      "metadata": {
        "id": "jZXoEeqQ9BVJ"
      },
      "id": "jZXoEeqQ9BVJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c_splitter.split_text(some_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrM6zwUV9EAt",
        "outputId": "c51f3786-d9c4-4b14-ceee-119a3016dcc9"
      },
      "id": "NrM6zwUV9EAt",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['When writing documents, writers will use document structure to group content. This can convey to the reader, which idea\\'s are related. For example, closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document. \\n\\n Paragraphs are often delimited with a carriage return or two carriage returns. Carriage returns are the \"backslash n\" you see embedded in this string. Sentences have a period at the end, but also,',\n",
              " 'have a space.and words are separated by space.']"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r_splitter.split_text(some_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZUV7ygE9K9D",
        "outputId": "92fd6d6a-72f0-440b-c156-4e1cac77f212"
      },
      "id": "lZUV7ygE9K9D",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"When writing documents, writers will use document structure to group content. This can convey to the reader, which idea's are related. For example, closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document.\",\n",
              " 'Paragraphs are often delimited with a carriage return or two carriage returns. Carriage returns are the \"backslash n\" you see embedded in this string. Sentences have a period at the end, but also, have a space.and words are separated by space.']"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"input your API_KEY\")\n",
        "# userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "model = ChatOpenAI(model=\"gpt-4o\")"
      ],
      "metadata": {
        "id": "uVjOxprm9NAs"
      },
      "id": "uVjOxprm9NAs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %pip install langchain_openai"
      ],
      "metadata": {
        "id": "o_eonWWIAZ3A"
      },
      "id": "o_eonWWIAZ3A",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(\"tell me a joke about {topic}\")\n",
        "\n",
        "chain = prompt | model | StrOutputParser()"
      ],
      "metadata": {
        "id": "fBWpLtATAHB0"
      },
      "id": "fBWpLtATAHB0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke({\"topic\": \"bears\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "ThCRigCKAs-4",
        "outputId": "d0c1c144-5523-418f-dc12-ad3ecdf05815"
      },
      "id": "ThCRigCKAs-4",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Sure, here's a bear-themed joke for you:\\n\\nWhy do bears never get lost?\\n\\nBecause they always follow their bear-ings! 🐻🧭\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import MarkdownHeaderTextSplitter"
      ],
      "metadata": {
        "id": "a8lROyq-Au_M"
      },
      "id": "a8lROyq-Au_M",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "markdown_document = \"\"\"# Title\\n\\n \\\n",
        "## Chapter 1\\n\\n \\\n",
        "Hi this is Jim\\n\\n Hi this is Joe\\n\\n \\\n",
        "### Section \\n\\n \\\n",
        "Hi this is Lance \\n\\n\n",
        "## Chapter 2\\n\\n \\\n",
        "Hi this is Molly\"\"\""
      ],
      "metadata": {
        "id": "pUiECsJECVKM"
      },
      "id": "pUiECsJECVKM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "headers_to_split_on = [\n",
        "    (\"#\", \"Header 1\"),\n",
        "    (\"##\", \"Header 2\"),\n",
        "    (\"###\", \"Header 3\"),\n",
        "]"
      ],
      "metadata": {
        "id": "979Y63chCXGe"
      },
      "id": "979Y63chCXGe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "markdown_splitter = MarkdownHeaderTextSplitter(\n",
        "    headers_to_split_on=headers_to_split_on\n",
        ")\n",
        "md_header_splits = markdown_splitter.split_text(markdown_document)"
      ],
      "metadata": {
        "id": "J8XkUsjjCZG6"
      },
      "id": "J8XkUsjjCZG6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "md_header_splits[0]"
      ],
      "metadata": {
        "id": "Q9Jx1WzcCbTZ",
        "outputId": "0156d616-cee1-4298-cc1c-bb96e4a9a772",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Q9Jx1WzcCbTZ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'Header 1': 'Title', 'Header 2': 'Chapter 1'}, page_content='Hi this is Jim  \\nHi this is Joe')"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HQJG5P60CdVp"
      },
      "id": "HQJG5P60CdVp",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}